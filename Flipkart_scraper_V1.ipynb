{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from operator import add\n",
    "from operator import iconcat\n",
    "import functools\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "main_url = 'https://www.flipkart.com/poco-x2-matrix-purple-64-gb/product-reviews/itm2db9fa45189d2?pid=MOBFZGJ6HY6H4JHU&lid=LSTMOBFZGJ6HY6H4JHU4GJFSE&marketplace=FLIPKART'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURLs(main_url):\n",
    "\n",
    "    #Get the total pages of review\n",
    "    response = requests.get(main_url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, features=\"lxml\")\n",
    "\n",
    "    total_pages = soup.find_all(\"div\", class_=\"_2zg3yZ _3KSYCY\")[0]\n",
    "    total_pages_count = total_pages.find_all(\"span\")[0].get_text().split()[3]\n",
    "    #Page nos have comma, so removing the comma\n",
    "    total_pages_count = int(re.sub(\",\",\"\",total_pages_count))\n",
    "    \n",
    "    #Generate pages having review URLs\n",
    "    review_urls = []    \n",
    "    for n in range(1,total_pages_count):\n",
    "        review_urls.append(main_url+'&page='+str(n))\n",
    "    return(review_urls) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objects(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, features=\"lxml\")\n",
    "    \n",
    "    #Review text\n",
    "    review = soup.find_all(\"div\", class_=\"qwjRop\")\n",
    "\n",
    "    #Review Heading\n",
    "    review_heading_obj = soup.find_all(\"p\", class_=\"_2xg6Ul\")\n",
    "\n",
    "    #Star rating\n",
    "    #star_count_obj=soup.find_all(\"div\", class_=\"hGSR34 E_uFuv\")\n",
    "    star_count_obj = soup.find_all(\"div\", class_=\"col _390CkK _1gY8H-\")\n",
    "    \n",
    "    return(soup,review,review_heading_obj,star_count_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(star_count_obj):\n",
    "    \n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    a=[]\n",
    "    b=[]\n",
    "    c=[]\n",
    "    p=[]\n",
    "    high_star_val=[]\n",
    "    star_count_list=[]\n",
    "\n",
    "    #Get the divs for each star as each star has a different class value.\n",
    "    for temp in star_count_obj:\n",
    "        two_star = temp.find_all(\"div\",class_=\"hGSR34 _1x2VEC E_uFuv\")\n",
    "        one_star = temp.find_all(\"div\",class_=\"hGSR34 _1nLEql E_uFuv\")\n",
    "        high_star = temp.find_all(\"div\",class_=\"hGSR34 E_uFuv\")\n",
    "\n",
    "    #Logic to preserve the order of star ratings in a page.\n",
    "    #Store the elements of each star value as a list. The list will have elements if respective star is present, else will be empty.    \n",
    "        x.append(two_star)\n",
    "        y.append(one_star)\n",
    "        z.append(high_star)\n",
    "\n",
    "    #If the list is empty, populate the position as 0, else populate with star value\n",
    "    for temp in x:\n",
    "        if temp:\n",
    "            a.append(2)\n",
    "        else:\n",
    "            a.append(0)\n",
    "\n",
    "    for temp in y:\n",
    "        if temp:\n",
    "            b.append(1)\n",
    "        else:\n",
    "            b.append(0)\n",
    "\n",
    "    for temp in z:\n",
    "        if temp:\n",
    "            p.append(temp)\n",
    "        else:\n",
    "            p.append(0)\n",
    "\n",
    "    #Since 3,4, and 5 stars have common class, we need to further drill down the star ratings from text.\n",
    "    for temp in p:\n",
    "        if temp:\n",
    "            new_string = str(temp)\n",
    "            high_star_val.append(int(new_string[28]))\n",
    "        else:\n",
    "            high_star_val.append(0)\n",
    "    \n",
    "    #Add all the list elements to get star ratings with order preserved.\n",
    "    my_val = list(map(add,a, b))\n",
    "    star_count_list = list(map(add,my_val,high_star_val))\n",
    "    return(star_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_details(star_count_obj,soup,review_heading_obj,review):\n",
    "\n",
    "    #Parse the required objects    \n",
    "    review_heading_obj = soup.find_all(\"p\", class_=\"_2xg6Ul\")\n",
    "    review = soup.find_all(\"div\", class_=\"qwjRop\")\n",
    "\n",
    "    star_count_list = []\n",
    "    review_heading_list = []\n",
    "    review_list = []\n",
    "\n",
    "\n",
    "    for words in review_heading_obj:\n",
    "        review_heading_list.append(words.text)    \n",
    "\n",
    "    for tag in review:\n",
    "        review_list.append(tag.text)\n",
    "    \n",
    "    star_count_list = get_ratings(star_count_obj)\n",
    "\n",
    "    return(star_count_list,review_heading_list,review_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://www.flipkart.com/asus-6z-black-64-gb/product-reviews/itmfg5hgqf3hwaj4?pid=MOBFG5HF4AG4DWYT&lid=LSTMOBFG5HF4AG4DWYTMJUBLX&marketplace=FLIPKART'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup,review,review_heading_obj,star_count_obj = get_objects(main_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_count_list,review_heading_list,review_list = populate_details(star_count_obj,soup,review_heading_obj,review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_func():\n",
    "    review_urls = getURLs(main_url)\n",
    "    #temp_review_urls = review_urls[0:250]\n",
    "    temp_review_urls =[]\n",
    "\n",
    "    if (len(review_urls) < 200):\n",
    "        temp_review_urls = review_urls\n",
    "    else:\n",
    "        temp_review_urls = review_urls[0:200]\n",
    "    \n",
    "    #Initialize all the lists\n",
    "    data_set = pd.DataFrame()\n",
    "    star_count_list_final = []\n",
    "    review_heading_list_final = []\n",
    "    review_list_final = []\n",
    "\n",
    "    for temp in temp_review_urls:\n",
    "        soup,review,review_heading_obj,star_count_obj = get_objects(temp)\n",
    "        temp_star_count_list,temp_review_heading_list,temp_review_list = populate_details(star_count_obj,soup,review_heading_obj,review)\n",
    "\n",
    "        star_count_list_final.append(temp_star_count_list)\n",
    "        review_heading_list_final.append(temp_review_heading_list)\n",
    "        review_list_final.append(temp_review_list)\n",
    "\n",
    "    star_count_list_final = remove_nestings(star_count_list_final)\n",
    "    review_heading_list_final = remove_nestings(review_heading_list_final)\n",
    "    review_list_final = remove_nestings(review_list_final)\n",
    "\n",
    "    data_set['Star_count'] = star_count_list_final\n",
    "    data_set['Heading'] = review_heading_list_final\n",
    "    data_set['Review'] = review_list_final\n",
    "    return(data_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nestings(a):\n",
    "    return functools.reduce(iconcat, a, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ds = main_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape full review\n"
   ]
  }
 ]
}